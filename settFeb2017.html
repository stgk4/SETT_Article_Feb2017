<!DOCTYPE HTML>
<html>

<head>
    <meta charset="utf-8">

    <meta name="description" content="Google prediction API" />
    <meta name="keywords" content="SETT, OCI, Machine Learning, Google, Prediction API" />
    <meta name="author" content="Srinivas Chakravarthi Thandu" />
    <title>SETT Feb 2017 - Prediction API</title>

    <link rel="alternate" type="application/rss+xml" title="RSS" 
href="http://ociweb.com/sett/rss.xml" />
    <link href="styles/SETT.css" rel="stylesheet" type="text/css" />


    <!--Used for syntax highlighting.  -->
    <link href="http://alexgorbatchev.com/pub/sh/current/styles/shCore.css" 
rel="stylesheet" type="text/css" />
    <link href="http://alexgorbatchev.com/pub/sh/current/styles/shThemeDefault.css" 
rel="stylesheet" type="text/css" />
    <style>
        del { background-color: rgba(200,50,50,0.4); color: maroon; }
        ins { background-color: rgba(50,200,50,0.4); color: purple; }
        .mikecomment { background-color: rgba(50,50,200,0.4); color: yellow; }
        .highlight { background-color: rgba(240,240,70,0.4); }
    </style>
</head>

<body>
    <!--#include virtual="header.shtml" -->

    <h1>On the capabilities of Google's Prediction API for building practical machine-learning based applications</h1>

    <p class="author">
        by
        <br/> Srinivas Chakravarthi Thandu, Software Engineer
        <br/>Object Computing, Inc. (OCI)
    </p>

    <h3>Introduction</h3>
      <span class='mikecomment'>Consider splitting this into 2 paragraphs.</span>
    <p>
	Application development has continued to evolve over the last several decades. We have come so far from building 
	applications on a single machine in a single location to a stage where we are building applications on 
	infrastructure which might be very remote to us. Even more today<del> , </del> we are able to leverage pre-built applications 
	which are offered as a service to make Machine Learning work for us. Enterprises or individuals trying to solve 
	a problem with machine learning<del> , </del> do not have to worry about fault tolerance aspects of the machines, performance 
	limitations, or tuning the machine learning algorithms. Instead<del> , </del> they can invest time on data preparation, 
	incorporating the domain knowledge in the machine learning system and acting on the offerings (prediction results) 
	from these API's to create business value. Many advanced machine learning capabilities are made available to 
	everyone by Prediction API's through a fast, reliable<ins> , </ins> and cost-effective infrastructure. There are several Prediction 
	API's available currently, such as 
	<a target="_blank" href="https://aws.amazon.com/machine-learning/">Amazon Machine Learning</a>, 
	<a target="_blank" href="https://bigml.com/api/">Big ML</a>, 
	<a target="_blank" href="https://cloud.google.com/prediction/">Google Prediction API</a> and many others. 
	While every Prediction API differs in terms of their services, 
	there is no single standard metric to evaluate the performance of these API's. A comparison study of some of the 
	Prediction API's can be found 
	<a target="_blank" href="https://www.programmableweb.com/news/comparing-four-machine-learning-apis-performance/elsewhere-web/2015/09/19">here</a>. 
 
	<del>However, it</del><ins>It</ins> is possible to identify an API or a combination of them that works better for the context of a specific application which needs expert knowledge and deeper look into 
	the context of the problem, details of which is out of the scope of the current topic<del> , </del> and will be the topic of a future article.  For the purposes of this article<del> , </del> we chose to 
	describe the capabilities of the Google Prediction API. In this article<del> , </del> you will learn about the possibilities the Google's Prediction API offers<del> , </del> with respect to a set of 
	representative use cases.
	</p>
	
	
	<h3>What is Google Prediction API?</h3>
	
	<p>
	Google’s Prediction API offers machine learning as a service. It learns from a user’s given training data and provides pattern matching and machine learning capabilities. The 
Prediction API can predict a numeric value or a categorical value derived from the data provided in the training set. Using these capabilities there is a possibility of 
building applications ranging from spam detection to recommendation engines without actually worrying about building a model.

	</p>
	
	<p>
	The following are a representative set of use cases that can be built leveraging the capabilities of Google’s Prediction API: 
	</p>
	<ul>
		<li> Predict future trends from a given historical series of data.
		<li> Detect if a given email is a spam.
		<li> Recommend a product/movie to the user based on the interests of a similar user.
		<li> Identify whether a given user will default based on the credit usage history of the user.
		<li> Detect activity from smartphones using labeled sensor datasets. 
	</ul>
	
	<p>
	On a given labeled dataset<del> , </del> the Prediction API performs the following specific tasks:  
	</p>
	<ul>
	<li>Given a new item, predict a numeric value for that item, based on similarly valued examples in its training data 
	(regression).</li>              	
	<li>Given a new item, choose a category that describes it best, given a set of similarly categorized items in its 
	training data (classification). </li>      	
	</ul>
	
	<p>
	The bottom line of all the above-discussed applications is the ability to predict a world state parameter (target label value) for an unknown example based on the past labeled data 
examples. The Prediction API will take care  of building suitable models using Google’s fast and reliable computing resources. Most prediction queries take less than 200ms.	
	</p>
	
	<h3>How does the Prediction API work?</h3>
	<p>
	The implementation of the Google's Prediction API is <del>basically </del>a black-box approach. In other words<del> , </del> there is no way to control the model-selection, 
        model-tuning<ins> , </ins> <span class='highlight'>and things that happen in the background during training</span><span class='mikecomment'>maybe "and other training activities during training"?</span>. The model configuration is restricted to specifying the class of problem whether it is "Classification" 
vs. "Regression" during the data preparation for the training process. At a very high level<del> , </del> the information flow in the Prediction API looks as shown in the following:
	</p>
	
	<div id="container">
      <a href="#">
	<figure>
	  <img src="./figures/prediction_api.jpg" alt="inception" width="1000" height="400"/>
	  <figcaption>Information flow of Prediction API</figcaption>
	</figure>
      </a>
    </div>
	
	<p>
	 Input features can contain any type of data<del> , and the</del><ins>. The</ins> API does not impose any constraints on input data types or any configuration process. The API will take care of value 
normalization, feature selection and even missing values in the dataset. The important step is data preparation, as per the specified format which that Prediction API will 
accept for training. The data simply looks like a big table<del> , </del> where each record is an input data example and the labels (target value) are specified in the very first column in 
the training set. The only difference between the training and testing sets is that the first column will not be present in the testing set. The training data looks as shown 
in the following figure.
	</p>
	
	<div id="container">
      <a href="#">
	<figure>
	  <img src="./figures/training_data.png" alt="inception" width="600" height="400"/>
	  <figcaption>Sample training data</figcaption>
	</figure>
      </a>
    </div>
	
	<p>
	The biggest disadvantage with this type of implementation<del> , however,</del> is <ins>that </ins>you cannot predict two different world state parameters (labels) at the same time, which otherwise can be 
done with your own model implementation.
	</p>
	
	<p>
        <span class='highlight'>For the project, you will be developing, you </span><span class='mikecomment'>Maybe something like: "To develop a project model you will "</span>need to enable the Prediction API. To use the Prediction API<del> , </del> the only cloud service required is “Cloud Storage”<ins> , </ins> which is enabled by 
default in your Google Cloud Project. You are required to create a bucket in the location where your training set is uploaded. <ins> The </ins>Prediction API offers a simple way to train machine 
learning models through a RESTful interface. To authorize the requests, your application must use “OAuth 2.0” protocol -- the API does not support any other types of 
protocols. The detailed information on the authorization is given in <a target="_blank" href="https://developers.google.com/identity/protocols/OAuth2">Google OAuth</a> documentation.
<div class='mikecomment'>I would mention here that an application wrapping a model could use the Identity provider service from google to enable the use of user Google logins in order to provide the authorization to the API.  This is well beyond the scope of the article though, so just a mention that perhaps the Google login might be used?</div> 

 
The training phase is initialized by calling the "trainedmodels.insert" method. The training phase is asynchronous, <del> where you can </del><ins> allowing you to </ins>poll the API using "prediction.trainedmodels.get" 
method to check the status of the training. In the response, when the "trainingStatus" property changes to "Done" from "Running", then the model training is completed. Only after 
this, can you start making predictions for new data examples.	
</p>
	
	<p>
        The API provides a "trainedmodels.analyze” method which specifies the "modelDescription" that contains the <span class='highlight'>confusion Matrix</span><span class='mikecomment'>Confusion Matrix or confusion matrix</span> in the JSON format. It will not <ins>directly </ins>provide any 
additional statistics like precision, recall, or F-score which  you would have to calculate manually.  
	</p>
	
	<p>
	For the resulting model which the API builds, you can make predictions for new example datasets by calling "trainedmodels.predict" method, this returns the parameters 
"outputLabel" (numeric or String) and "outputMulti" which provide probability measures for each prediction class. The API assigns final predicted labels based on a voting 
mechanism where a class with highest probability score is predicted as “outputLabel”. The “outputMulti” is useful in making multiple predictions, for example: “top three 
predicted labels”.  The trained model remains until it is explicitly deleted. Apart from the training session, it does not continue to learn from the Predict queries. <del>However, the</del>
The API provides a “trainedmodels.update” method which can be used to make update calls with additional examples. The applications that constantly fetch the user data can take 
advantage of this method to achieve better performance by improving the models on a continuous basis.
	</p>
	
	<h3>Who is the audience for Prediction API's?</h3>
	
	<p>
	Traditionally<del> , </del> to implement a machine learning capability<del> , </del> you normally start with preprocessing your data by performing some steps like dealing with missing data, input 
normalization, dataset splitting into training and validation sets. Then comes the step of model selection, based on the correlations in your training data, in which you 
identify a model that fits your scenario.
	</p>
	
	<p>
	With the Prediction API, you don’t need to worry about these steps, since the API automatically trains and tests a lot of complex models, tuned with different parameters, 
choosing the best one for the final evaluation. The model which API finally comes up with would have been the one you end up after so many iterations of tuning the model 
parameters. Even, the model evaluation is handled by the API itself. All you need to worry and work about is providing a valid data source in the required format to the API. 
Google's black-box implementation approach for Prediction API is intended to ease the implementation for non-coders. In a way, the mathematical expertise required to build, 
analyze the machine learning models, is eliminated by the capabilities of the API. One can invest more time in problem formulation, data collection and make a flawless end to 
end implementation, by leveraging the algorithmic capabilities of Prediction API.
	</p>
	
	
	<h3>Using a Hosted Model</h3>
	
	<p>
	If you have a specific problem and do not have time, resources, or expertise to build a model, you can use from the gallery of user-submitted models which are hosted 
	<a target="_blank" href="https://cloud.google.com/prediction/docs/gallery">here</a>. These models may be a paid service or free to use, depending upon the hosted owner. 
	The gallery currently consists of models built by the Prediction API team itself and does not 
	contain any models built other users (as of the time of this article is published). The Prediction API enables customers to expose their model for paid use by other 
	API users in the future. As described in the documentation, the only method call supported on a hosted model is “predict”. 	
	The gallery will list the URL required for a prediction call to a specific model. Note that hosted models are versioned; this means that when a model is retrained, it will get a 
	new path that includes the version number. You will need to periodically check the gallery to ensure that you're using the latest version of a hosted model. The model version 
	number appears in the access URL. Different versions might return different scores for the same input.  
	</p>
	

<h3>Use case 1: Predicting user rating from product reviews</h3>
	
	<p>
	To illustrate the use of the Prediction API for regression, a problem involving prediction of product rating (real-valued) for a given product review is demonstrated. 
	Typically, the traditional review problem aims at recommending products to a user based on the user ratings and preferences. 
	Here, the current problem approaches in a kind of reverse format which involves predicting a reasonable rating for a given user product review using the model 
	trained from amazon food product reviews data which can be found
	<a target="_blank" href="http://snap.stanford.edu/data/web-FineFoods.html">here</a>. 
	 	
	For working with a machine learning problem, one of the most important and time-consuming aspects is defining the problem appropriately and preparing the dataset 
	accordingly. Before all that, the problem should be analyzed and assessed to ensure that the problem is appropriate for applying a machine learning approach in the 
	first place. After all, not every problem is solvable using machine learning.  
	</p>
	
	<p>
	There are two main things you need to clarify and make sure before starting the problem:   
	</p>
	<ul>
	
	      	
	<li>Determine if the problem requires regression or classification, and clearly identify what are you going to predict/classify</li>                   	
	<li>Identify all necessary assumptions, ensuring they do not affect the scope of the problem</li>      
	
	</ul>
	
	<p>
	For the current problem, since we are going to predict a rating which is a real value, this is clearly a regression problem. The second point above is 
	important as you can have redundant data which will, in turn, affects the model accuracy. A detailed description and scope of machine learning algorithms were described in 
	our previous SETT article which can be found 
	<a target="_blank" href="https://www.ociweb.com/resources/publications/sett/february-2015-welcome-to-the-machine-learning/">here</a>.
	
	Typically, if the features are too specific to the current dataset, you may end up with a very large generalization error, resulting in overfitting. This is the piece you need to 
	handle yourself, to better assist the Prediction API in predicting accurate labels for your test inputs. Although this preprocessing step is not mandatory for using Prediction API, 
	you need it to build a good model corresponding to your training set.
	</p>
	
	<p>
	The dataset chosen for the current problem contains 568,454 product reviews collected from 256,059 users for 74,258 products. Each row represents a product review
	and each column represents a meta-data corresponding to the review. Usually, there may be columns not of interest to a specific problem, so filtering 
	those and including only relevant features will lead to a better model. Accordingly, we prepare our data and make sure to include the label in the first column as mentioned in 
	the API documentation. At this point, each row consists of a rating, review summary and review text. We now setup the project, which involves 1) creating a 
	Google Cloud Platform project (you can also build on top of an existing one), 2) enabling billing and 3) enabling the Prediction API for the project. 
	</p>
	Note: A globally unique project id is chosen for the project name and a number is assigned when the cloud platform project is created. Detailed descriptions of these steps are 
	provided <a target="_blank" href="https://cloud.google.com/resource-manager/docs/creating-project">here</a>.
	

	<p>
	Next, you must create a bucket with globally unique name and add the training set file as 'CSV' file to the bucket. For training the model, the 
	"prediction.trainedmodels.insert" method is called,   passing a unique name for this predictive model, and the bucket location of the training data as shown below. A full list 
	of the methods is provided <a target="_blank" href="https://developers.google.com/apis-explorer/#p/prediction/v1.6/prediction">here</a>.
	</p>

<div>
    <pre class="prettyprint">
	POST https://www.googleapis.com/prediction/v1.6/projects/oci-analytics/trainedmodels?key={YOUR_API_KEY}
	{
		"id": "rating-predictor",
		"storageDataLocation": "oci-prediction_api-demo/product_reviews_amazon.csv"
	}
    </pre>
    <figcaption>Request format for initializing the training
</div>

<p> A successful response looks like: </p>
<div>
    <pre class="prettyprint">
	Response 200
	- Show headers -
	{
		"kind": "prediction#training",
		"id": "rating-predictor",
		"selfLink": "https://www.googleapis.com/prediction/v1.6/projects/oci-analytics/trainedmodels/rating-predictor",
		"storageDataLocation": "oci-prediction_api-demo/product_reviews_amazon.csv"
	}
    </pre>
    <figcaption>Response to the training request
</div>

<p>
To check the status of Training, use the "prediction.trainedmodels.get" method by passing the ID of the predictive model as shown below.
<!-- GET https://www.googleapis.com/prediction/v1.6/projects/[PROJECT_ID]/trainedmodels/sentiment-identifier -->
</p>

<div>
    <pre class="prettyprint">
		GET https://www.googleapis.com/prediction/v1.6/projects/oci-analytics/trainedmodels/rating-predictor?key={YOUR_API_KEY}
    </pre>
    <figcaption>Querying about the status of training
</div>

<p>
After the training is complete, you can send queries to the service to be evaluated against the predictive model. To do so, call the "prediction.trainedmodels.predict" method, 
passing the name of the model and the query.
</p>


<div>
    <pre class="prettyprint">
		POST https://www.googleapis.com/prediction/v1.6/projects/oci-analytics/trainedmodels/rating-predictor/predict?key={YOUR_API_KEY}
		{
			"input": {
			"csvInstance": [
			"product seems ok, it should have looked as expected, parts were little delicate, overall it tastes just ok"
			]
			}
		}
    </pre>
    <figcaption>Sending a prediction query to the Prediction API
</div>

<div>
    <pre class="prettyprint">
	200
	- Show headers -
	{
		"kind": "prediction#output",
		"id": "rating-predictor",
		"selfLink": "https://www.googleapis.com/prediction/v1.6/projects/oci-analytics/trainedmodels/rating-predictor/predict",
		"outputValue": "3.756272"
	}
    </pre>
    <figcaption>Prediction response containing the prediction label and probability scores
</div>
	
<h3>Use case 2: Sentiment analysis</h3>
	
	<p>
	To illustrate the use of the Prediction API for classification, a simple binary classification problem is shown to classify positive or negative sentiment from the Twitter sentiment analysis 
	corpus dataset found <a target="_blank" href="http://thinknook.com/twitter-sentiment-analysis-training-corpus-dataset-2012-09-22/">here</a>.
	</p>
	
	<p>
	For the current problem, since we are going to identify a predefined label "Negative" or "Positive", this is a classification problem. 
	The dataset chosen for the current problem contains about 1.5 million rows and 4 columns. A classification model is built and the following demonstrates the classification 
	scenario on the resultant model:
	</p>


<div>
    <pre class="prettyprint">
		POST https://www.googleapis.com/prediction/v1.6/projects/oci-analytics/trainedmodels/sentiment-identifier_12500/predict?key={YOUR_API_KEY}
		{
			"input": {
				"csvInstance": [
					"I am worried about today's game..."
				]
			}
		}
    </pre>
    <figcaption>Sending a prediction query to the Prediction API
</div>

<div>
    <pre class="prettyprint">
		200
		- Show headers -
		{
			"kind": "prediction#output",
			"id": "sentiment-identifier_12500",
			"selfLink": "https://www.googleapis.com/prediction/v1.6/projects/oci-analytics/trainedmodels/sentiment-identifier_12500/predict",
			"outputLabel": "NEGATIVE",
			"outputMulti": [
			{
				"label": "NEGATIVE",
				"score": "0.696235"
			},
			{
				"label": "POSITIVE",
				"score": "0.303765"
			}
			]
		}
    </pre>
    <figcaption>Prediction response containing the prediction label and probability scores
</div>
	
	<h3>Conclusions</h3>
	<p>
	As of now, the Google Prediction API provides a machine learning capability that is abstracted and simplified substantially for developers. The control is only	in the data 
preparation and adding additional datasets for updating the model, these forms the either end-points of the machine learning pipeline. Key advantages of this approach are that 
it saves a lot of time in building the models, and it provides flexibility for adding additional datasets even after the training is completed, enabling simple model updates on 
the fly.
	</p>
    
   <!--  <h2>Conclusion</h2>

    This article only examines basic ideas and
    usages of GCP to build machine learning workflow. -->


<h3>Acknowledgements</h3>

 <p>
 I want to thank my colleagues Yong Fu, Huang-Ming Huang, Kevin Stanley, Mike Martinez, Carl Turza from OCI for very useful and professional comments that greatly improved the quality of this article.
</p>


    <!--#include virtual="footer.shtml" -->
    <script src="http://alexgorbatchev.com/pub/sh/current/scripts/shCore.js" 
type="text/javascript"></script>
    <script src="http://alexgorbatchev.com/pub/sh/current/scripts/shAutoloader.js" 
type="text/javascript"></script>

    <script src="http://alexgorbatchev.com/pub/sh/current/scripts/shBrushJava.js" 
type="text/javascript"></script>
    <script src="http://alexgorbatchev.com/pub/sh/current/scripts/shBrushXml.js" 
type="text/javascript"></script>
    <script src="http://alexgorbatchev.com/pub/sh/current/scripts/shBrushPhp.js" 
type="text/javascript"></script>
    <script src="http://alexgorbatchev.com/pub/sh/current/scripts/shBrushScala.js" 
type="text/javascript"></script>
    <script src="http://alexgorbatchev.com/pub/sh/current/scripts/shBrushJScript.js" 
type="text/javascript"></script>
    <script src="http://alexgorbatchev.com/pub/sh/current/scripts/shBrushPlain.js" 
type="text/javascript"></script>
    <script src="http://alexgorbatchev.com/pub/sh/current/scripts/shBrushCpp.js" 
type="text/javascript"></script>
    <script src="http://alexgorbatchev.com/pub/sh/current/scripts/shBrushCSharp.js" 
type="text/javascript"></script>
    <script 
src="https://cdn.rawgit.com/google/code-prettify/master/loader/run_prettify.js"></scrip
t>
    <script type="text/javascript">
        SyntaxHighlighter.all()
    </script>

    <h2>Further Reading</h2>
    <ul>
	
	<li><a href="https://www.ociweb.com/resources/publications/sett/february-2015-welcome-to-the-machine-learning/"> 
	Welcome to Machine Learning, SETT Article, February 2015</a>.
	</li>
	
    <li><a href="https://cloud.google.com/ml/docs/concepts/technical-overview">
	Overview of Google Cloud Machine Learning</a>.
    </li>
    
    </ul> 
</body>

</html>



